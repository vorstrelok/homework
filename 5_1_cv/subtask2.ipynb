{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = np.loadtxt('../../data/digit-recognizer/train.csv', delimiter=',', skiprows=1)\n",
    "test = np.loadtxt('../../data/digit-recognizer/test.csv', delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сохраняем разметку в отдельную переменную\n",
    "train_label = train[:, 0]\n",
    "# приводим размерность к удобному для обаботки виду\n",
    "train_img = np.resize(train[:, 1:], (train.shape[0], 28, 28))\n",
    "test_img = np.resize(test, (test.shape[0], 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Предобработаем изображения\n",
    "def crop_normalize_blur(image):\n",
    "    return cv2.GaussianBlur(normalize(image[3:-4, 4:-3]), (3,3), 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Вычисляем X и Y составляющие градиента с помощью оператора Собеля\n",
    "def sobel(image):\n",
    "    sobel_x = cv2.Sobel(image, cv2.CV_64F, dx=1, dy=0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(image, cv2.CV_64F, dx=0, dy=1, ksize=3)\n",
    "    return sobel_x, sobel_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_histogram(gradient, theta, number_of_bins=16):\n",
    "    # Гистограммы вычисляются с учетом длины вектора градиента\n",
    "    hist_columns = []\n",
    "    for gradient_row, theta_row in zip(np.split(gradient, 3), np.split(theta, 3)):\n",
    "        hist_row = []\n",
    "        for gradient_cell, theta_cell in zip(np.split(gradient_row, 3, axis=1), np.split(theta_row, 3, axis=1)):\n",
    "            hist, borders = np.histogram(\n",
    "                theta_cell,\n",
    "                bins=number_of_bins,\n",
    "                range=(0., 2. * np.pi),\n",
    "                weights=gradient_cell\n",
    "            )\n",
    "            hist_row.append(hist)\n",
    "        hist_columns.append(hist_row)\n",
    "    return np.array(hist_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def blocks_normalize(histogram_grid):\n",
    "    blocks = [\n",
    "        histogram_grid[:2, :2, :],\n",
    "        histogram_grid[1:, :2, :],\n",
    "        histogram_grid[:2, 1:, :],\n",
    "        histogram_grid[1:, 1:, :],\n",
    "    ]\n",
    "    features = np.stack(normalize(block.reshape(1, -1)) for block in blocks).reshape(-1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(images):\n",
    "    for image in images:\n",
    "#         Вычисляем угол и длину вектора градиента\n",
    "        gradient, theta = cv2.cartToPolar(*sobel(crop_normalize_blur(image)))\n",
    "        features = blocks_normalize(gradient_histogram(gradient, theta))\n",
    "        yield features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.7 s, sys: 19.8 ms, total: 39.7 s\n",
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = np.stack(get_features(train_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводим информацию о модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(260, input_dim=train_data.shape[1], activation='relu'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Dense(312, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.05))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.05))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 260)               66820     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 260)               1040      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 312)               81432     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 312)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               40064     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 190,646\n",
      "Trainable params: 190,126\n",
      "Non-trainable params: 520\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Запускаем обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train_labels = np_utils.to_categorical(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 2s - loss: 0.2961 - acc: 0.9134     \n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0745 - acc: 0.9761     \n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0499 - acc: 0.9842     \n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0362 - acc: 0.9882     \n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0269 - acc: 0.9915     \n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0208 - acc: 0.9934     \n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0169 - acc: 0.9944     \n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0128 - acc: 0.9960     \n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0104 - acc: 0.9970     \n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0082 - acc: 0.9978     \n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0097 - acc: 0.9968     \n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0112 - acc: 0.9958     \n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0101 - acc: 0.9966     \n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0070 - acc: 0.9975     \n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0087 - acc: 0.9972     \n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0105 - acc: 0.9964     \n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0083 - acc: 0.9968     \n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0054 - acc: 0.9982     \n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0063 - acc: 0.9975     \n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 1s - loss: 0.0072 - acc: 0.9972     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8866350198>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, y_train_labels, batch_size=500, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = keras.models.Sequential()\n",
    "lenet.add(keras.layers.Conv2D(6, (5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "lenet.add(keras.layers.MaxPool2D(pool_size=(2,2), padding='valid'))\n",
    "lenet.add(keras.layers.Conv2D(16, (5,5), padding='valid', activation='relu'))\n",
    "lenet.add(keras.layers.MaxPool2D(pool_size=(2,2), padding='valid'))\n",
    "lenet.add(keras.layers.Flatten())\n",
    "lenet.add(keras.layers.Dense(120, activation='relu'))\n",
    "lenet.add(keras.layers.Dense(84, activation='relu'))\n",
    "lenet.add(keras.layers.noise.GaussianDropout(0.05))\n",
    "lenet.add(keras.layers.Dense(10, activation='softmax'))\n",
    "lenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "gaussian_dropout_4 (Gaussian (None, 84)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42000/42000 [==============================] - 8s - loss: 2.9894 - acc: 0.7043     \n",
      "Epoch 2/20\n",
      "42000/42000 [==============================] - 8s - loss: 0.2202 - acc: 0.9370     \n",
      "Epoch 3/20\n",
      "42000/42000 [==============================] - 8s - loss: 0.1365 - acc: 0.9598     \n",
      "Epoch 4/20\n",
      "42000/42000 [==============================] - 8s - loss: 0.0968 - acc: 0.9704     \n",
      "Epoch 5/20\n",
      "42000/42000 [==============================] - 8s - loss: 0.0740 - acc: 0.9773     \n",
      "Epoch 6/20\n",
      "42000/42000 [==============================] - 8s - loss: 0.0556 - acc: 0.9819     \n",
      "Epoch 7/20\n",
      "42000/42000 [==============================] - 8s - loss: 0.0475 - acc: 0.9846     \n",
      "Epoch 8/20\n",
      "42000/42000 [==============================] - 8s - loss: 0.0395 - acc: 0.9865     \n",
      "Epoch 9/20\n",
      "42000/42000 [==============================] - 8s - loss: 0.0321 - acc: 0.9898     \n",
      "Epoch 10/20\n",
      "42000/42000 [==============================] - 8s - loss: 0.0257 - acc: 0.9916     \n",
      "Epoch 11/20\n",
      "42000/42000 [==============================] - 9s - loss: 0.0224 - acc: 0.9922     \n",
      "Epoch 12/20\n",
      "42000/42000 [==============================] - 9s - loss: 0.0194 - acc: 0.9932     \n",
      "Epoch 13/20\n",
      "42000/42000 [==============================] - 9s - loss: 0.0148 - acc: 0.9949     \n",
      "Epoch 14/20\n",
      "42000/42000 [==============================] - 9s - loss: 0.0138 - acc: 0.9954     \n",
      "Epoch 15/20\n",
      "42000/42000 [==============================] - 9s - loss: 0.0125 - acc: 0.9957     \n",
      "Epoch 16/20\n",
      "42000/42000 [==============================] - 9s - loss: 0.0112 - acc: 0.9963     \n",
      "Epoch 17/20\n",
      "42000/42000 [==============================] - 9s - loss: 0.0092 - acc: 0.9973     \n",
      "Epoch 18/20\n",
      "42000/42000 [==============================] - 9s - loss: 0.0113 - acc: 0.9962     \n",
      "Epoch 19/20\n",
      "42000/42000 [==============================] - 8s - loss: 0.0086 - acc: 0.9969     \n",
      "Epoch 20/20\n",
      "42000/42000 [==============================] - 8s - loss: 0.0095 - acc: 0.9969     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f885a5dc860>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet.fit(np.resize(train[:, 1:], (train.shape[0], 28, 28, 1)), y_train_labels, batch_size=500, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказываем класс объекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40672/42000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pred_val_model = model.predict_classes(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your submission scored 0.98528"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41984/42000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pred_val_lenet = lenet.predict_classes(np.resize(train[:, 1:], (train.shape[0], 28, 28, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your submission scored 0.98028"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оцениваем качество решение на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.998666666667\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      4132\n",
      "        1.0       1.00      1.00      1.00      4684\n",
      "        2.0       1.00      1.00      1.00      4177\n",
      "        3.0       1.00      1.00      1.00      4351\n",
      "        4.0       1.00      1.00      1.00      4072\n",
      "        5.0       1.00      1.00      1.00      3795\n",
      "        6.0       1.00      1.00      1.00      4137\n",
      "        7.0       1.00      1.00      1.00      4401\n",
      "        8.0       1.00      1.00      1.00      4063\n",
      "        9.0       1.00      1.00      1.00      4188\n",
      "\n",
      "avg / total       1.00      1.00      1.00     42000\n",
      "\n",
      "[[4131    0    0    0    1    0    0    0    0    0]\n",
      " [   0 4677    2    0    0    0    0    4    0    1]\n",
      " [   0    0 4176    0    0    0    0    1    0    0]\n",
      " [   0    0    1 4350    0    0    0    0    0    0]\n",
      " [   0    0    0    0 4066    0    0    0    0    6]\n",
      " [   0    0    0    9    0 3786    0    0    0    0]\n",
      " [   1    0    0    0    0    2 4132    0    2    0]\n",
      " [   0    0    4    0    0    0    0 4397    0    0]\n",
      " [   3    0    1    2    0    1    0    0 4055    1]\n",
      " [   2    0    0    0    2    2    0    7    1 4174]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %s' % accuracy_score(train_label, pred_val_model))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(train_label, pred_val_model))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(train_label, pred_val_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.998333333333\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      4132\n",
      "        1.0       1.00      1.00      1.00      4684\n",
      "        2.0       1.00      1.00      1.00      4177\n",
      "        3.0       1.00      1.00      1.00      4351\n",
      "        4.0       1.00      1.00      1.00      4072\n",
      "        5.0       1.00      1.00      1.00      3795\n",
      "        6.0       1.00      1.00      1.00      4137\n",
      "        7.0       1.00      1.00      1.00      4401\n",
      "        8.0       1.00      1.00      1.00      4063\n",
      "        9.0       1.00      1.00      1.00      4188\n",
      "\n",
      "avg / total       1.00      1.00      1.00     42000\n",
      "\n",
      "[[4132    0    0    0    0    0    0    0    0    0]\n",
      " [   0 4683    0    0    0    0    0    1    0    0]\n",
      " [   0    1 4176    0    0    0    0    0    0    0]\n",
      " [   2    0    5 4344    0    0    0    0    0    0]\n",
      " [   0    1    0    1 4068    0    0    1    0    1]\n",
      " [   2    0    1    1    0 3788    1    0    2    0]\n",
      " [  15    0    1    0    0    1 4120    0    0    0]\n",
      " [   0    1    2    0    0    0    0 4398    0    0]\n",
      " [   0    0    2    7    0    1    0    0 4052    1]\n",
      " [   1    0    1    8    5    0    0    4    0 4169]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('Accuracy: %s' % accuracy_score(train_label, pred_val_lenet))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(train_label, pred_val_lenet))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(train_label, pred_val_lenet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказания на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26880/28000 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict_classes(np.stack(get_features(test_img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27808/28000 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "pred_lenet = lenet.predict_classes(np.resize(test, (test.shape[0], 28, 28, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируем предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzsAAAC3CAYAAAA1tUARAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAACgkJjsAAAAACgkJjsAAAAACun/AWXGJwYhGpMYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f885993c9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "for i, img in enumerate(test_img[0:5], 1):\n",
    "    subplot = fig.add_subplot(1, 7, i)\n",
    "    plt.imshow(img, cmap='gray');\n",
    "    subplot.set_title('%s' % pred_lenet[i - 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Готовим файл для отправки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submit.txt', 'w') as dst:\n",
    "    dst.write('ImageId,Label\\n')\n",
    "    for i, p in enumerate(pred_lenet, 1):\n",
    "        dst.write('%s,%s\\n' % (i, int(p)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
